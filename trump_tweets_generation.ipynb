{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation - **Generating Trump Tweets**"
      ],
      "metadata": {
        "id": "211B8HleQmAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras import Sequential, layers, losses, optimizers\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "9N7nBUbxQtCw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = '/content/archive (17).zip'\n",
        "\n",
        "ref = zipfile.ZipFile(file)\n",
        "ref.extractall()\n",
        "ref.close()"
      ],
      "metadata": {
        "id": "3ohqieg4Rnwa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('trumptweets.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "FEcPkHbkRuix",
        "outputId": "7582fdbe-d883-4e5d-fc62-adbbb635adae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                               link  \\\n",
              "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
              "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
              "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
              "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
              "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
              "\n",
              "                                             content                 date  \\\n",
              "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 20:54:25   \n",
              "1  Donald Trump will be appearing on The View tom...  2009-05-05 03:00:10   \n",
              "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 15:38:08   \n",
              "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 22:40:15   \n",
              "4  \"My persona will never be that of a wallflower...  2009-05-12 16:07:28   \n",
              "\n",
              "   retweets  favorites mentions hashtags  geo  \n",
              "0       500        868      NaN      NaN  NaN  \n",
              "1        33        273      NaN      NaN  NaN  \n",
              "2        12         18      NaN      NaN  NaN  \n",
              "3        11         24      NaN      NaN  NaN  \n",
              "4      1399       1965      NaN      NaN  NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cb60f1e-4789-40c0-a1b2-950f026094da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>link</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>retweets</th>\n",
              "      <th>favorites</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>geo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1698308935</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
              "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
              "      <td>2009-05-04 20:54:25</td>\n",
              "      <td>500</td>\n",
              "      <td>868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1701461182</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
              "      <td>Donald Trump will be appearing on The View tom...</td>\n",
              "      <td>2009-05-05 03:00:10</td>\n",
              "      <td>33</td>\n",
              "      <td>273</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1737479987</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
              "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
              "      <td>2009-05-08 15:38:08</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1741160716</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
              "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
              "      <td>2009-05-08 22:40:15</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1773561338</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
              "      <td>\"My persona will never be that of a wallflower...</td>\n",
              "      <td>2009-05-12 16:07:28</td>\n",
              "      <td>1399</td>\n",
              "      <td>1965</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cb60f1e-4789-40c0-a1b2-950f026094da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cb60f1e-4789-40c0-a1b2-950f026094da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cb60f1e-4789-40c0-a1b2-950f026094da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = df['content']"
      ],
      "metadata": {
        "id": "T3TSqycPR01E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcTW4ohtR-OO",
        "outputId": "fde1fb9e-cb9e-4cbf-937e-846f08cbe304"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41122"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEyWzBvzR_d3",
        "outputId": "48462ca1-efea-4990-8ab8-7501282a5fda"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Be sure to tune in and watch Donald Trump on L...\n",
              "1    Donald Trump will be appearing on The View tom...\n",
              "2    Donald Trump reads Top Ten Financial Tips on L...\n",
              "3    New Blog Post: Celebrity Apprentice Finale and...\n",
              "4    \"My persona will never be that of a wallflower...\n",
              "5    Miss USA Tara Conner will not be fired - \"I've...\n",
              "6    Listen to an interview with Donald Trump discu...\n",
              "7    \"Strive for wholeness and keep your sense of w...\n",
              "8    Enter the \"Think Like A Champion\" signed book ...\n",
              "9    \"When the achiever achieves, it's not a platea...\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = max([len(x.split()) for x in tweets])\n",
        "maxlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRtXlZF3SDRp",
        "outputId": "b8ab36a8-b0bc-4a70-d535-cc82f5771e34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create corpus\n",
        "corpus = []\n",
        "\n",
        "for tweet in tweets:\n",
        "  corpus.append(tweet.lower())"
      ],
      "metadata": {
        "id": "mAbYa46ZSKky"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoOvZSUfSdu0",
        "outputId": "2e0325d6-34d0-4658-ce12-f39812fbc311"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41122"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mini = corpus[:1000]"
      ],
      "metadata": {
        "id": "7z1deyJfSeux"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=10000, oov_token='<oov>')\n",
        "tokenizer.fit_on_texts(mini)"
      ],
      "metadata": {
        "id": "mzTqHdcHSmYv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index) + 1\n",
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH4Q2Bs-S5wc",
        "outputId": "53e6b998-82b4-4fc3-c3d7-f828d88ff9ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3603"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "\n",
        "for tweet in mini:\n",
        "  token_list = tokenizer.texts_to_sequences([tweet])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram = token_list[:i + 1]\n",
        "    sequences.append(n_gram)"
      ],
      "metadata": {
        "id": "ODgQZKZiTCI4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = max([len(x) for x in sequences])\n",
        "maxlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKA5wSZFUGEp",
        "outputId": "b2f8e0c9-b1f4-4153-8485-bcfc367a37ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(pad_sequences(sequences, maxlen, padding='pre'))\n",
        "sequences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtPy6Q2LUKxf",
        "outputId": "3dca8b9f-d18d-42de-8f41-724cffa15756"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  14, 120],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  14, 120,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  14, 120,   3,  94],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  14, 120,   3,  94,  11],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         14, 120,   3,  94,  11,   5],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14,\n",
              "        120,   3,  94,  11,   5,  37],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 120,\n",
              "          3,  94,  11,   5,  37,  36],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 120,   3,\n",
              "         94,  11,   5,  37,  36,  18],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 120,   3,  94,\n",
              "         11,   5,  37,  36,  18,   6],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,  14, 120,   3,  94,  11,\n",
              "          5,  37,  36,  18,   6, 270]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = sequences[:, :-1]\n",
        "labels = sequences[:, -1]"
      ],
      "metadata": {
        "id": "rOjrs9fVUWo3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "ZIrlinB0UhE3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = layers.Embedding(input_dim=total_words, output_dim=128, input_length = maxlen - 1)"
      ],
      "metadata": {
        "id": "2To0ng7nUlnj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    embedding,\n",
        "    layers.LSTM(32),\n",
        "    layers.Dense(16, 'relu'),\n",
        "    layers.Dense(8, 'relu'),\n",
        "    layers.Dense(total_words, 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss=losses.CategoricalCrossentropy(),\n",
        "              optimizer=optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ml_6nKHsU161"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5,\n",
        "                             restore_best_weights=True, verbose=False)\n",
        "\n",
        "history = model.fit(sequences, labels, epochs=100,\n",
        "                    callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83GtVxp5VHV4",
        "outputId": "ed59c4c6-25d0-43dd-e417-0d2323a32bf2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "553/553 [==============================] - 35s 47ms/step - loss: 6.3380 - accuracy: 0.0397\n",
            "Epoch 2/100\n",
            "553/553 [==============================] - 6s 11ms/step - loss: 5.0733 - accuracy: 0.1021\n",
            "Epoch 3/100\n",
            "553/553 [==============================] - 6s 11ms/step - loss: 4.0055 - accuracy: 0.3015\n",
            "Epoch 4/100\n",
            "553/553 [==============================] - 7s 12ms/step - loss: 3.4158 - accuracy: 0.4109\n",
            "Epoch 5/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 3.0114 - accuracy: 0.4875\n",
            "Epoch 6/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 2.6183 - accuracy: 0.5475\n",
            "Epoch 7/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 2.3406 - accuracy: 0.5908\n",
            "Epoch 8/100\n",
            "553/553 [==============================] - 6s 11ms/step - loss: 2.1457 - accuracy: 0.6229\n",
            "Epoch 9/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 2.0016 - accuracy: 0.6447\n",
            "Epoch 10/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.8934 - accuracy: 0.6614\n",
            "Epoch 11/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.8298 - accuracy: 0.6643\n",
            "Epoch 12/100\n",
            "553/553 [==============================] - 6s 10ms/step - loss: 1.7328 - accuracy: 0.6836\n",
            "Epoch 13/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 1.6852 - accuracy: 0.6870\n",
            "Epoch 14/100\n",
            "553/553 [==============================] - 5s 8ms/step - loss: 1.6412 - accuracy: 0.6946\n",
            "Epoch 15/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.5638 - accuracy: 0.7098\n",
            "Epoch 16/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.5219 - accuracy: 0.7155\n",
            "Epoch 17/100\n",
            "553/553 [==============================] - 4s 6ms/step - loss: 1.5383 - accuracy: 0.7045\n",
            "Epoch 18/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.4587 - accuracy: 0.7235\n",
            "Epoch 19/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.4093 - accuracy: 0.7300\n",
            "Epoch 20/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.4277 - accuracy: 0.7219\n",
            "Epoch 21/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 1.3604 - accuracy: 0.7410\n",
            "Epoch 22/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.3305 - accuracy: 0.7439\n",
            "Epoch 23/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.3598 - accuracy: 0.7344\n",
            "Epoch 24/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 1.3115 - accuracy: 0.7445\n",
            "Epoch 25/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 1.2520 - accuracy: 0.7573\n",
            "Epoch 26/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.2376 - accuracy: 0.7597\n",
            "Epoch 27/100\n",
            "553/553 [==============================] - 5s 10ms/step - loss: 1.2938 - accuracy: 0.7363\n",
            "Epoch 28/100\n",
            "553/553 [==============================] - 5s 8ms/step - loss: 1.2057 - accuracy: 0.7649\n",
            "Epoch 29/100\n",
            "553/553 [==============================] - 5s 8ms/step - loss: 1.1749 - accuracy: 0.7698\n",
            "Epoch 30/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 1.2192 - accuracy: 0.7541\n",
            "Epoch 31/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.1860 - accuracy: 0.7640\n",
            "Epoch 32/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.1307 - accuracy: 0.7752\n",
            "Epoch 33/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.1529 - accuracy: 0.7688\n",
            "Epoch 34/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.1732 - accuracy: 0.7619\n",
            "Epoch 35/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 1.0914 - accuracy: 0.7829\n",
            "Epoch 36/100\n",
            "553/553 [==============================] - 6s 11ms/step - loss: 1.0881 - accuracy: 0.7805\n",
            "Epoch 37/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 1.1367 - accuracy: 0.7686\n",
            "Epoch 38/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 1.0893 - accuracy: 0.7782\n",
            "Epoch 39/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.0642 - accuracy: 0.7864\n",
            "Epoch 40/100\n",
            "553/553 [==============================] - 4s 6ms/step - loss: 1.0385 - accuracy: 0.7924\n",
            "Epoch 41/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 1.1055 - accuracy: 0.7725\n",
            "Epoch 42/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 1.0554 - accuracy: 0.7853\n",
            "Epoch 43/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.0083 - accuracy: 0.7959\n",
            "Epoch 44/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 1.0019 - accuracy: 0.7965\n",
            "Epoch 45/100\n",
            "553/553 [==============================] - 5s 8ms/step - loss: 1.0613 - accuracy: 0.7802\n",
            "Epoch 46/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.0191 - accuracy: 0.7926\n",
            "Epoch 47/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 0.9855 - accuracy: 0.7995\n",
            "Epoch 48/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 0.9651 - accuracy: 0.8067\n",
            "Epoch 49/100\n",
            "553/553 [==============================] - 4s 6ms/step - loss: 0.9927 - accuracy: 0.7950\n",
            "Epoch 50/100\n",
            "553/553 [==============================] - 6s 10ms/step - loss: 1.0516 - accuracy: 0.7801\n",
            "Epoch 51/100\n",
            "553/553 [==============================] - 5s 10ms/step - loss: 0.9490 - accuracy: 0.8091\n",
            "Epoch 52/100\n",
            "553/553 [==============================] - 5s 8ms/step - loss: 0.9355 - accuracy: 0.8120\n",
            "Epoch 53/100\n",
            "553/553 [==============================] - 5s 10ms/step - loss: 0.9423 - accuracy: 0.8082\n",
            "Epoch 54/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 1.0273 - accuracy: 0.7857\n",
            "Epoch 55/100\n",
            "553/553 [==============================] - 4s 6ms/step - loss: 0.9516 - accuracy: 0.8065\n",
            "Epoch 56/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 0.9153 - accuracy: 0.8145\n",
            "Epoch 57/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 0.9284 - accuracy: 0.8112\n",
            "Epoch 58/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 0.9697 - accuracy: 0.7999\n",
            "Epoch 59/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 0.9410 - accuracy: 0.8067\n",
            "Epoch 60/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 0.9089 - accuracy: 0.8169\n",
            "Epoch 61/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 0.9099 - accuracy: 0.8138\n",
            "Epoch 62/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 0.9303 - accuracy: 0.8072\n",
            "Epoch 63/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 0.9229 - accuracy: 0.8094\n",
            "Epoch 64/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 0.8863 - accuracy: 0.8181\n",
            "Epoch 65/100\n",
            "553/553 [==============================] - 4s 8ms/step - loss: 0.8836 - accuracy: 0.8198\n",
            "Epoch 66/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 0.8927 - accuracy: 0.8177\n",
            "Epoch 67/100\n",
            "553/553 [==============================] - 3s 6ms/step - loss: 0.9526 - accuracy: 0.8034\n",
            "Epoch 68/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 0.8970 - accuracy: 0.8147\n",
            "Epoch 69/100\n",
            "553/553 [==============================] - 4s 6ms/step - loss: 0.8727 - accuracy: 0.8248\n",
            "Epoch 70/100\n",
            "553/553 [==============================] - 4s 6ms/step - loss: 0.8675 - accuracy: 0.8238\n",
            "Epoch 71/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 0.8676 - accuracy: 0.8233\n",
            "Epoch 72/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 0.9291 - accuracy: 0.8079\n",
            "Epoch 73/100\n",
            "553/553 [==============================] - 4s 7ms/step - loss: 0.8787 - accuracy: 0.8190\n",
            "Epoch 74/100\n",
            "553/553 [==============================] - 5s 9ms/step - loss: 0.8662 - accuracy: 0.8234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_words = 50\n",
        "suffixes = ['s', 'es', 'ed', 'ing', 'ly', 'er', 'est', 'ible', 'ful', 'ment', 'ity', 'tion', 'ance', 'ence', 'ize', 'ise', 'ify', 'fy', 'al', 'ary', 'ic', 'ous', 'ive', 'less', 'ness', 'ize', 'ise', 'en']\n",
        "\n",
        "words = []\n",
        "for k, v in word_index.items():\n",
        "  words.append(k)\n",
        "\n",
        "words = [word for word in words if word not in suffixes]\n",
        "words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYZ3dzVfVSKH",
        "outputId": "4b02e2be-1949-4af4-decd-2cbe6abcf2a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<oov>', 'the', 'to', 'http', 'and', 'on', 'is', 'a', 'of', 'in']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(steps=next_words, prompt=''):\n",
        "\n",
        "  for _ in range(next_words):\n",
        "    tokens = tokenizer.texts_to_sequences([prompt])[0]\n",
        "    tokens = np.array(pad_sequences([tokens], maxlen-1, padding='pre'))\n",
        "    pred = model.predict(tokens, verbose=False)\n",
        "    idx = np.argmax(pred)\n",
        "    word = ''\n",
        "\n",
        "    if words[idx] != '<oov>':\n",
        "      word = words[idx]\n",
        "      prompt += \" \" + word\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "0XmLiOMzWDFb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = str(input(\"Prompt: \"))\n",
        "generate(40, prompt=seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "U7cUGtyuXWjq",
        "outputId": "a23291f1-e471-4602-af06-0ec39686f9df"
      },
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Taxes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Taxes looking then up only money lawrence taxes some gretawire usa 11 tough americans morning pqpfvm currently armed tele anywhere children's george award jon attack pass laughing energy hawaii ride wall counting solutions gcqjpr currently armed tele anywhere children's george award jon attack pass laughing energy hawaii ride wall counting solutions\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}